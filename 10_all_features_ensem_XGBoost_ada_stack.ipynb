{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0879b00",
   "metadata": {},
   "source": [
    "# XGBoost and AdaBoost ensemble (stacking classifier) with all features of the prepared files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e36ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklift.models import ClassTransformation\n",
    "from sklift import metrics\n",
    "from sklift.viz import plot_qini_curve\n",
    "import chime\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d9ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext chime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e51bc427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regular_points_received_mean</th>\n",
       "      <th>regular_points_received_sum</th>\n",
       "      <th>express_points_received_mean</th>\n",
       "      <th>express_points_received_sum</th>\n",
       "      <th>regular_points_spent_mean</th>\n",
       "      <th>regular_points_spent_sum</th>\n",
       "      <th>express_points_spent_mean</th>\n",
       "      <th>express_points_spent_sum</th>\n",
       "      <th>purchase_mean</th>\n",
       "      <th>purchase_sum</th>\n",
       "      <th>first_issue_date</th>\n",
       "      <th>first_redeem_date</th>\n",
       "      <th>age</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>no_redeem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000012768d</th>\n",
       "      <td>6.425000</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>700.750000</td>\n",
       "      <td>2803.00</td>\n",
       "      <td>17383</td>\n",
       "      <td>17535</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000036f903</th>\n",
       "      <td>1.715625</td>\n",
       "      <td>54.9</td>\n",
       "      <td>1.875</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306.406250</td>\n",
       "      <td>9805.00</td>\n",
       "      <td>17266</td>\n",
       "      <td>17279</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001f552b0</th>\n",
       "      <td>5.260000</td>\n",
       "      <td>78.9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>410.345333</td>\n",
       "      <td>6155.18</td>\n",
       "      <td>17347</td>\n",
       "      <td>17771</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00020e7b18</th>\n",
       "      <td>15.894444</td>\n",
       "      <td>286.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-32.888889</td>\n",
       "      <td>-592.0</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>1434.422778</td>\n",
       "      <td>25819.61</td>\n",
       "      <td>17497</td>\n",
       "      <td>17541</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000220a0a7</th>\n",
       "      <td>6.940000</td>\n",
       "      <td>104.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>573.771333</td>\n",
       "      <td>8606.57</td>\n",
       "      <td>17509</td>\n",
       "      <td>17808</td>\n",
       "      <td>46.379533</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffd5cd0c6</th>\n",
       "      <td>1.950000</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>318.423889</td>\n",
       "      <td>5731.63</td>\n",
       "      <td>17343</td>\n",
       "      <td>17797</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffd63dfe3</th>\n",
       "      <td>1.625000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.127500</td>\n",
       "      <td>1340.51</td>\n",
       "      <td>17312</td>\n",
       "      <td>17578</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffd8c9d7d</th>\n",
       "      <td>2.200000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>327.306000</td>\n",
       "      <td>1636.53</td>\n",
       "      <td>17582</td>\n",
       "      <td>17712</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffe0abb97</th>\n",
       "      <td>2.466667</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.888889</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-16.666667</td>\n",
       "      <td>-150.0</td>\n",
       "      <td>301.824444</td>\n",
       "      <td>2716.42</td>\n",
       "      <td>17497</td>\n",
       "      <td>17573</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffeca6d22</th>\n",
       "      <td>2.962500</td>\n",
       "      <td>47.4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.053750</td>\n",
       "      <td>2832.86</td>\n",
       "      <td>17528</td>\n",
       "      <td>18220</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140027 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            regular_points_received_mean  regular_points_received_sum  \\\n",
       "client_id                                                               \n",
       "000012768d                      6.425000                         25.7   \n",
       "000036f903                      1.715625                         54.9   \n",
       "0001f552b0                      5.260000                         78.9   \n",
       "00020e7b18                     15.894444                        286.1   \n",
       "000220a0a7                      6.940000                        104.1   \n",
       "...                                  ...                          ...   \n",
       "fffd5cd0c6                      1.950000                         35.1   \n",
       "fffd63dfe3                      1.625000                          6.5   \n",
       "fffd8c9d7d                      2.200000                         11.0   \n",
       "fffe0abb97                      2.466667                         22.2   \n",
       "fffeca6d22                      2.962500                         47.4   \n",
       "\n",
       "            express_points_received_mean  express_points_received_sum  \\\n",
       "client_id                                                               \n",
       "000012768d                         0.000                          0.0   \n",
       "000036f903                         1.875                         60.0   \n",
       "0001f552b0                         0.000                          0.0   \n",
       "00020e7b18                         0.000                          0.0   \n",
       "000220a0a7                         0.000                          0.0   \n",
       "...                                  ...                          ...   \n",
       "fffd5cd0c6                         0.000                          0.0   \n",
       "fffd63dfe3                         0.000                          0.0   \n",
       "fffd8c9d7d                         0.000                          0.0   \n",
       "fffe0abb97                         0.000                          0.0   \n",
       "fffeca6d22                         0.000                          0.0   \n",
       "\n",
       "            regular_points_spent_mean  regular_points_spent_sum  \\\n",
       "client_id                                                         \n",
       "000012768d                   0.000000                       0.0   \n",
       "000036f903                   0.000000                       0.0   \n",
       "0001f552b0                   0.000000                       0.0   \n",
       "00020e7b18                 -32.888889                    -592.0   \n",
       "000220a0a7                   0.000000                       0.0   \n",
       "...                               ...                       ...   \n",
       "fffd5cd0c6                   0.000000                       0.0   \n",
       "fffd63dfe3                   0.000000                       0.0   \n",
       "fffd8c9d7d                   0.000000                       0.0   \n",
       "fffe0abb97                  -2.888889                     -26.0   \n",
       "fffeca6d22                   0.000000                       0.0   \n",
       "\n",
       "            express_points_spent_mean  express_points_spent_sum  \\\n",
       "client_id                                                         \n",
       "000012768d                   0.000000                       0.0   \n",
       "000036f903                   0.000000                       0.0   \n",
       "0001f552b0                   0.000000                       0.0   \n",
       "00020e7b18                  -1.666667                     -30.0   \n",
       "000220a0a7                   0.000000                       0.0   \n",
       "...                               ...                       ...   \n",
       "fffd5cd0c6                   0.000000                       0.0   \n",
       "fffd63dfe3                   0.000000                       0.0   \n",
       "fffd8c9d7d                   0.000000                       0.0   \n",
       "fffe0abb97                 -16.666667                    -150.0   \n",
       "fffeca6d22                   0.000000                       0.0   \n",
       "\n",
       "            purchase_mean  purchase_sum  first_issue_date  first_redeem_date  \\\n",
       "client_id                                                                      \n",
       "000012768d     700.750000       2803.00             17383              17535   \n",
       "000036f903     306.406250       9805.00             17266              17279   \n",
       "0001f552b0     410.345333       6155.18             17347              17771   \n",
       "00020e7b18    1434.422778      25819.61             17497              17541   \n",
       "000220a0a7     573.771333       8606.57             17509              17808   \n",
       "...                   ...           ...               ...                ...   \n",
       "fffd5cd0c6     318.423889       5731.63             17343              17797   \n",
       "fffd63dfe3     335.127500       1340.51             17312              17578   \n",
       "fffd8c9d7d     327.306000       1636.53             17582              17712   \n",
       "fffe0abb97     301.824444       2716.42             17497              17573   \n",
       "fffeca6d22     177.053750       2832.86             17528              18220   \n",
       "\n",
       "                  age  gender_F  gender_M  no_redeem  \n",
       "client_id                                             \n",
       "000012768d  45.000000         0         0          0  \n",
       "000036f903  72.000000         1         0          0  \n",
       "0001f552b0  33.000000         1         0          0  \n",
       "00020e7b18  73.000000         0         0          0  \n",
       "000220a0a7  46.379533         0         1          0  \n",
       "...               ...       ...       ...        ...  \n",
       "fffd5cd0c6  47.000000         0         1          0  \n",
       "fffd63dfe3  31.000000         0         0          0  \n",
       "fffd8c9d7d  48.000000         1         0          0  \n",
       "fffe0abb97  35.000000         1         0          0  \n",
       "fffeca6d22  77.000000         1         0          1  \n",
       "\n",
       "[140027 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients = pd.read_csv('clients_train_modified.csv', index_col='client_id')\n",
    "clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b33f702",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = clients.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf45508",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8522825a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7456b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regular_points_received_mean</th>\n",
       "      <th>regular_points_received_sum</th>\n",
       "      <th>express_points_received_mean</th>\n",
       "      <th>express_points_received_sum</th>\n",
       "      <th>regular_points_spent_mean</th>\n",
       "      <th>regular_points_spent_sum</th>\n",
       "      <th>express_points_spent_mean</th>\n",
       "      <th>express_points_spent_sum</th>\n",
       "      <th>purchase_mean</th>\n",
       "      <th>purchase_sum</th>\n",
       "      <th>first_issue_date</th>\n",
       "      <th>first_redeem_date</th>\n",
       "      <th>age</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>no_redeem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000012768d</th>\n",
       "      <td>0.326493</td>\n",
       "      <td>-0.544865</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>0.547587</td>\n",
       "      <td>-0.653612</td>\n",
       "      <td>-0.771133</td>\n",
       "      <td>-0.856385</td>\n",
       "      <td>-0.087757</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000036f903</th>\n",
       "      <td>-0.597875</td>\n",
       "      <td>-0.239623</td>\n",
       "      <td>3.369176</td>\n",
       "      <td>7.499476</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.504430</td>\n",
       "      <td>0.138021</td>\n",
       "      <td>-1.344979</td>\n",
       "      <td>-1.862848</td>\n",
       "      <td>1.615961</td>\n",
       "      <td>1.309908</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001f552b0</th>\n",
       "      <td>0.097824</td>\n",
       "      <td>0.011260</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.227145</td>\n",
       "      <td>-0.274621</td>\n",
       "      <td>-0.947701</td>\n",
       "      <td>0.071448</td>\n",
       "      <td>-0.844965</td>\n",
       "      <td>1.309908</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00020e7b18</th>\n",
       "      <td>2.185181</td>\n",
       "      <td>2.177224</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>-3.206022</td>\n",
       "      <td>-4.001476</td>\n",
       "      <td>-0.403913</td>\n",
       "      <td>-1.443925</td>\n",
       "      <td>2.504855</td>\n",
       "      <td>1.948604</td>\n",
       "      <td>-0.212002</td>\n",
       "      <td>-0.832796</td>\n",
       "      <td>1.679061</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000220a0a7</th>\n",
       "      <td>0.427579</td>\n",
       "      <td>0.274688</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>0.208837</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>-0.153146</td>\n",
       "      <td>0.216913</td>\n",
       "      <td>-0.000708</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>2.226620</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffd5cd0c6</th>\n",
       "      <td>-0.551871</td>\n",
       "      <td>-0.446602</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.472370</td>\n",
       "      <td>-0.322507</td>\n",
       "      <td>-0.967320</td>\n",
       "      <td>0.173667</td>\n",
       "      <td>0.038444</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>2.226620</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffd63dfe3</th>\n",
       "      <td>-0.615663</td>\n",
       "      <td>-0.745572</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.427809</td>\n",
       "      <td>-0.818959</td>\n",
       "      <td>-1.119365</td>\n",
       "      <td>-0.687331</td>\n",
       "      <td>-0.971167</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffd8c9d7d</th>\n",
       "      <td>-0.502801</td>\n",
       "      <td>-0.698532</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.448675</td>\n",
       "      <td>-0.785491</td>\n",
       "      <td>0.204895</td>\n",
       "      <td>-0.160510</td>\n",
       "      <td>0.101545</td>\n",
       "      <td>1.309908</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffe0abb97</th>\n",
       "      <td>-0.450459</td>\n",
       "      <td>-0.581452</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.113449</td>\n",
       "      <td>0.363488</td>\n",
       "      <td>-6.261521</td>\n",
       "      <td>-8.803480</td>\n",
       "      <td>-0.516653</td>\n",
       "      <td>-0.663401</td>\n",
       "      <td>-0.212002</td>\n",
       "      <td>-0.706988</td>\n",
       "      <td>-0.718764</td>\n",
       "      <td>1.309908</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffeca6d22</th>\n",
       "      <td>-0.353135</td>\n",
       "      <td>-0.318025</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.849513</td>\n",
       "      <td>-0.650237</td>\n",
       "      <td>-0.059957</td>\n",
       "      <td>1.836689</td>\n",
       "      <td>1.931464</td>\n",
       "      <td>1.309908</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>3.214739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140027 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            regular_points_received_mean  regular_points_received_sum  \\\n",
       "client_id                                                               \n",
       "000012768d                      0.326493                    -0.544865   \n",
       "000036f903                     -0.597875                    -0.239623   \n",
       "0001f552b0                      0.097824                     0.011260   \n",
       "00020e7b18                      2.185181                     2.177224   \n",
       "000220a0a7                      0.427579                     0.274688   \n",
       "...                                  ...                          ...   \n",
       "fffd5cd0c6                     -0.551871                    -0.446602   \n",
       "fffd63dfe3                     -0.615663                    -0.745572   \n",
       "fffd8c9d7d                     -0.502801                    -0.698532   \n",
       "fffe0abb97                     -0.450459                    -0.581452   \n",
       "fffeca6d22                     -0.353135                    -0.318025   \n",
       "\n",
       "            express_points_received_mean  express_points_received_sum  \\\n",
       "client_id                                                               \n",
       "000012768d                     -0.072084                    -0.102507   \n",
       "000036f903                      3.369176                     7.499476   \n",
       "0001f552b0                     -0.072084                    -0.102507   \n",
       "00020e7b18                     -0.072084                    -0.102507   \n",
       "000220a0a7                     -0.072084                    -0.102507   \n",
       "...                                  ...                          ...   \n",
       "fffd5cd0c6                     -0.072084                    -0.102507   \n",
       "fffd63dfe3                     -0.072084                    -0.102507   \n",
       "fffd8c9d7d                     -0.072084                    -0.102507   \n",
       "fffe0abb97                     -0.072084                    -0.102507   \n",
       "fffeca6d22                     -0.072084                    -0.102507   \n",
       "\n",
       "            regular_points_spent_mean  regular_points_spent_sum  \\\n",
       "client_id                                                         \n",
       "000012768d                   0.433102                  0.563999   \n",
       "000036f903                   0.433102                  0.563999   \n",
       "0001f552b0                   0.433102                  0.563999   \n",
       "00020e7b18                  -3.206022                 -4.001476   \n",
       "000220a0a7                   0.433102                  0.563999   \n",
       "...                               ...                       ...   \n",
       "fffd5cd0c6                   0.433102                  0.563999   \n",
       "fffd63dfe3                   0.433102                  0.563999   \n",
       "fffd8c9d7d                   0.433102                  0.563999   \n",
       "fffe0abb97                   0.113449                  0.363488   \n",
       "fffeca6d22                   0.433102                  0.563999   \n",
       "\n",
       "            express_points_spent_mean  express_points_spent_sum  \\\n",
       "client_id                                                         \n",
       "000012768d                   0.246932                  0.395964   \n",
       "000036f903                   0.246932                  0.395964   \n",
       "0001f552b0                   0.246932                  0.395964   \n",
       "00020e7b18                  -0.403913                 -1.443925   \n",
       "000220a0a7                   0.246932                  0.395964   \n",
       "...                               ...                       ...   \n",
       "fffd5cd0c6                   0.246932                  0.395964   \n",
       "fffd63dfe3                   0.246932                  0.395964   \n",
       "fffd8c9d7d                   0.246932                  0.395964   \n",
       "fffe0abb97                  -6.261521                 -8.803480   \n",
       "fffeca6d22                   0.246932                  0.395964   \n",
       "\n",
       "            purchase_mean  purchase_sum  first_issue_date  first_redeem_date  \\\n",
       "client_id                                                                      \n",
       "000012768d       0.547587     -0.653612         -0.771133          -0.856385   \n",
       "000036f903      -0.504430      0.138021         -1.344979          -1.862848   \n",
       "0001f552b0      -0.227145     -0.274621         -0.947701           0.071448   \n",
       "00020e7b18       2.504855      1.948604         -0.212002          -0.832796   \n",
       "000220a0a7       0.208837      0.002529         -0.153146           0.216913   \n",
       "...                   ...           ...               ...                ...   \n",
       "fffd5cd0c6      -0.472370     -0.322507         -0.967320           0.173667   \n",
       "fffd63dfe3      -0.427809     -0.818959         -1.119365          -0.687331   \n",
       "fffd8c9d7d      -0.448675     -0.785491          0.204895          -0.160510   \n",
       "fffe0abb97      -0.516653     -0.663401         -0.212002          -0.706988   \n",
       "fffeca6d22      -0.849513     -0.650237         -0.059957           1.836689   \n",
       "\n",
       "                 age  gender_F  gender_M  no_redeem  \n",
       "client_id                                            \n",
       "000012768d -0.087757 -0.763412 -0.449111  -0.311067  \n",
       "000036f903  1.615961  1.309908 -0.449111  -0.311067  \n",
       "0001f552b0 -0.844965  1.309908 -0.449111  -0.311067  \n",
       "00020e7b18  1.679061 -0.763412 -0.449111  -0.311067  \n",
       "000220a0a7 -0.000708 -0.763412  2.226620  -0.311067  \n",
       "...              ...       ...       ...        ...  \n",
       "fffd5cd0c6  0.038444 -0.763412  2.226620  -0.311067  \n",
       "fffd63dfe3 -0.971167 -0.763412 -0.449111  -0.311067  \n",
       "fffd8c9d7d  0.101545  1.309908 -0.449111  -0.311067  \n",
       "fffe0abb97 -0.718764  1.309908 -0.449111  -0.311067  \n",
       "fffeca6d22  1.931464  1.309908 -0.449111   3.214739  \n",
       "\n",
       "[140027 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_scaled = pd.DataFrame(scaler.transform(clients),\n",
    "                              columns=x_cols,\n",
    "                             index=clients.index)\n",
    "clients_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc6262cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment_flg</th>\n",
       "      <th>purchased</th>\n",
       "      <th>regular_points_received_mean</th>\n",
       "      <th>regular_points_received_sum</th>\n",
       "      <th>express_points_received_mean</th>\n",
       "      <th>express_points_received_sum</th>\n",
       "      <th>regular_points_spent_mean</th>\n",
       "      <th>regular_points_spent_sum</th>\n",
       "      <th>express_points_spent_mean</th>\n",
       "      <th>express_points_spent_sum</th>\n",
       "      <th>purchase_mean</th>\n",
       "      <th>purchase_sum</th>\n",
       "      <th>first_issue_date</th>\n",
       "      <th>first_redeem_date</th>\n",
       "      <th>age</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>no_redeem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ad6561e2d8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.457165</td>\n",
       "      <td>0.203605</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.256063</td>\n",
       "      <td>0.070434</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.601460</td>\n",
       "      <td>0.250673</td>\n",
       "      <td>-0.182574</td>\n",
       "      <td>-0.309907</td>\n",
       "      <td>0.227746</td>\n",
       "      <td>1.309908</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7c1ccbf93f</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.012094</td>\n",
       "      <td>-0.715257</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.186716</td>\n",
       "      <td>-0.874302</td>\n",
       "      <td>-0.295381</td>\n",
       "      <td>-0.663742</td>\n",
       "      <td>-1.412871</td>\n",
       "      <td>1.309908</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b58fadcab6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.390384</td>\n",
       "      <td>0.142974</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>-0.602976</td>\n",
       "      <td>-1.818994</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.176185</td>\n",
       "      <td>0.631720</td>\n",
       "      <td>-0.334618</td>\n",
       "      <td>0.142215</td>\n",
       "      <td>-0.655663</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e99e6fabb9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.729281</td>\n",
       "      <td>-0.671353</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.732479</td>\n",
       "      <td>-0.645811</td>\n",
       "      <td>0.621791</td>\n",
       "      <td>-0.282386</td>\n",
       "      <td>2.057665</td>\n",
       "      <td>1.309908</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27fb6f8520</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.396808</td>\n",
       "      <td>0.045757</td>\n",
       "      <td>1.151475</td>\n",
       "      <td>2.431487</td>\n",
       "      <td>0.418348</td>\n",
       "      <td>0.533151</td>\n",
       "      <td>-0.403913</td>\n",
       "      <td>-2.670518</td>\n",
       "      <td>-0.442714</td>\n",
       "      <td>0.147202</td>\n",
       "      <td>-0.864322</td>\n",
       "      <td>-0.935015</td>\n",
       "      <td>-0.781865</td>\n",
       "      <td>1.309908</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999d284453</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.758315</td>\n",
       "      <td>-0.452875</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>0.664302</td>\n",
       "      <td>-0.633827</td>\n",
       "      <td>1.445775</td>\n",
       "      <td>0.940309</td>\n",
       "      <td>1.615961</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f634deea4e</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.721304</td>\n",
       "      <td>-0.211399</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.238944</td>\n",
       "      <td>-0.153212</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.790863</td>\n",
       "      <td>0.222140</td>\n",
       "      <td>0.126420</td>\n",
       "      <td>-0.592975</td>\n",
       "      <td>-0.718764</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16cb4f99b0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.250437</td>\n",
       "      <td>-0.558455</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.125167</td>\n",
       "      <td>-0.615512</td>\n",
       "      <td>0.219609</td>\n",
       "      <td>1.156541</td>\n",
       "      <td>0.227746</td>\n",
       "      <td>1.309908</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23c2b72b2e</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.618261</td>\n",
       "      <td>-0.527094</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.777196</td>\n",
       "      <td>-0.578119</td>\n",
       "      <td>-0.942797</td>\n",
       "      <td>-1.163041</td>\n",
       "      <td>0.543249</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430184499</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.705920</td>\n",
       "      <td>1.894979</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>0.767917</td>\n",
       "      <td>1.774937</td>\n",
       "      <td>-1.138983</td>\n",
       "      <td>-0.644084</td>\n",
       "      <td>1.048055</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>2.226620</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140027 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            treatment_flg  purchased  regular_points_received_mean  \\\n",
       "client_id                                                            \n",
       "ad6561e2d8              1          1                     -0.457165   \n",
       "7c1ccbf93f              1          1                     -0.012094   \n",
       "b58fadcab6              1          1                     -0.390384   \n",
       "e99e6fabb9              0          0                     -0.729281   \n",
       "27fb6f8520              1          1                     -0.396808   \n",
       "...                   ...        ...                           ...   \n",
       "999d284453              1          1                      0.758315   \n",
       "f634deea4e              0          1                     -0.721304   \n",
       "16cb4f99b0              0          1                     -0.250437   \n",
       "23c2b72b2e              1          1                     -0.618261   \n",
       "1430184499              0          1                      0.705920   \n",
       "\n",
       "            regular_points_received_sum  express_points_received_mean  \\\n",
       "client_id                                                               \n",
       "ad6561e2d8                     0.203605                     -0.072084   \n",
       "7c1ccbf93f                    -0.715257                     -0.072084   \n",
       "b58fadcab6                     0.142974                     -0.072084   \n",
       "e99e6fabb9                    -0.671353                     -0.072084   \n",
       "27fb6f8520                     0.045757                      1.151475   \n",
       "...                                 ...                           ...   \n",
       "999d284453                    -0.452875                     -0.072084   \n",
       "f634deea4e                    -0.211399                     -0.072084   \n",
       "16cb4f99b0                    -0.558455                     -0.072084   \n",
       "23c2b72b2e                    -0.527094                     -0.072084   \n",
       "1430184499                     1.894979                     -0.072084   \n",
       "\n",
       "            express_points_received_sum  regular_points_spent_mean  \\\n",
       "client_id                                                            \n",
       "ad6561e2d8                    -0.102507                   0.256063   \n",
       "7c1ccbf93f                    -0.102507                   0.433102   \n",
       "b58fadcab6                    -0.102507                  -0.602976   \n",
       "e99e6fabb9                    -0.102507                   0.433102   \n",
       "27fb6f8520                     2.431487                   0.418348   \n",
       "...                                 ...                        ...   \n",
       "999d284453                    -0.102507                   0.433102   \n",
       "f634deea4e                    -0.102507                   0.238944   \n",
       "16cb4f99b0                    -0.102507                   0.433102   \n",
       "23c2b72b2e                    -0.102507                   0.433102   \n",
       "1430184499                    -0.102507                   0.433102   \n",
       "\n",
       "            regular_points_spent_sum  express_points_spent_mean  \\\n",
       "client_id                                                         \n",
       "ad6561e2d8                  0.070434                   0.246932   \n",
       "7c1ccbf93f                  0.563999                   0.246932   \n",
       "b58fadcab6                 -1.818994                   0.246932   \n",
       "e99e6fabb9                  0.563999                   0.246932   \n",
       "27fb6f8520                  0.533151                  -0.403913   \n",
       "...                              ...                        ...   \n",
       "999d284453                  0.563999                   0.246932   \n",
       "f634deea4e                 -0.153212                   0.246932   \n",
       "16cb4f99b0                  0.563999                   0.246932   \n",
       "23c2b72b2e                  0.563999                   0.246932   \n",
       "1430184499                  0.563999                   0.246932   \n",
       "\n",
       "            express_points_spent_sum  purchase_mean  purchase_sum  \\\n",
       "client_id                                                           \n",
       "ad6561e2d8                  0.395964      -0.601460      0.250673   \n",
       "7c1ccbf93f                  0.395964      -0.186716     -0.874302   \n",
       "b58fadcab6                  0.395964      -0.176185      0.631720   \n",
       "e99e6fabb9                  0.395964      -0.732479     -0.645811   \n",
       "27fb6f8520                 -2.670518      -0.442714      0.147202   \n",
       "...                              ...            ...           ...   \n",
       "999d284453                  0.395964       0.664302     -0.633827   \n",
       "f634deea4e                  0.395964      -0.790863      0.222140   \n",
       "16cb4f99b0                  0.395964      -0.125167     -0.615512   \n",
       "23c2b72b2e                  0.395964      -0.777196     -0.578119   \n",
       "1430184499                  0.395964       0.767917      1.774937   \n",
       "\n",
       "            first_issue_date  first_redeem_date       age  gender_F  gender_M  \\\n",
       "client_id                                                                       \n",
       "ad6561e2d8         -0.182574          -0.309907  0.227746  1.309908 -0.449111   \n",
       "7c1ccbf93f         -0.295381          -0.663742 -1.412871  1.309908 -0.449111   \n",
       "b58fadcab6         -0.334618           0.142215 -0.655663 -0.763412 -0.449111   \n",
       "e99e6fabb9          0.621791          -0.282386  2.057665  1.309908 -0.449111   \n",
       "27fb6f8520         -0.864322          -0.935015 -0.781865  1.309908 -0.449111   \n",
       "...                      ...                ...       ...       ...       ...   \n",
       "999d284453          1.445775           0.940309  1.615961 -0.763412 -0.449111   \n",
       "f634deea4e          0.126420          -0.592975 -0.718764 -0.763412 -0.449111   \n",
       "16cb4f99b0          0.219609           1.156541  0.227746  1.309908 -0.449111   \n",
       "23c2b72b2e         -0.942797          -1.163041  0.543249 -0.763412 -0.449111   \n",
       "1430184499         -1.138983          -0.644084  1.048055 -0.763412  2.226620   \n",
       "\n",
       "            no_redeem  \n",
       "client_id              \n",
       "ad6561e2d8  -0.311067  \n",
       "7c1ccbf93f  -0.311067  \n",
       "b58fadcab6  -0.311067  \n",
       "e99e6fabb9  -0.311067  \n",
       "27fb6f8520  -0.311067  \n",
       "...               ...  \n",
       "999d284453  -0.311067  \n",
       "f634deea4e  -0.311067  \n",
       "16cb4f99b0  -0.311067  \n",
       "23c2b72b2e  -0.311067  \n",
       "1430184499  -0.311067  \n",
       "\n",
       "[140027 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv('train.csv', index_col='client_id')\\\n",
    "    .join(clients_scaled, how='left')\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60d31e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train, indices_val = train_test_split(df_full.index, \n",
    "                                              test_size=0.2, \n",
    "                                              random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ebf60d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112021,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "823b22e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28006,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7aa399dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regular_points_received_mean</th>\n",
       "      <th>regular_points_received_sum</th>\n",
       "      <th>express_points_received_mean</th>\n",
       "      <th>express_points_received_sum</th>\n",
       "      <th>regular_points_spent_mean</th>\n",
       "      <th>regular_points_spent_sum</th>\n",
       "      <th>express_points_spent_mean</th>\n",
       "      <th>express_points_spent_sum</th>\n",
       "      <th>purchase_mean</th>\n",
       "      <th>purchase_sum</th>\n",
       "      <th>first_issue_date</th>\n",
       "      <th>first_redeem_date</th>\n",
       "      <th>age</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>no_redeem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fd1ab717e8</th>\n",
       "      <td>-0.344139</td>\n",
       "      <td>0.318593</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.674769</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>1.146590</td>\n",
       "      <td>0.881336</td>\n",
       "      <td>1.426659</td>\n",
       "      <td>1.309908</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5be3f83065</th>\n",
       "      <td>1.015586</td>\n",
       "      <td>0.640561</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>0.588284</td>\n",
       "      <td>0.162789</td>\n",
       "      <td>1.852862</td>\n",
       "      <td>1.113294</td>\n",
       "      <td>1.300457</td>\n",
       "      <td>1.309908</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1c48fc99b2</th>\n",
       "      <td>-0.516362</td>\n",
       "      <td>0.411629</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.189674</td>\n",
       "      <td>-0.369147</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.434654</td>\n",
       "      <td>1.097419</td>\n",
       "      <td>-1.085032</td>\n",
       "      <td>-1.548328</td>\n",
       "      <td>0.732551</td>\n",
       "      <td>1.309908</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fcce9d3197</th>\n",
       "      <td>-0.494128</td>\n",
       "      <td>0.195242</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.026531</td>\n",
       "      <td>-0.654489</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.421486</td>\n",
       "      <td>0.670231</td>\n",
       "      <td>-0.834894</td>\n",
       "      <td>-1.438246</td>\n",
       "      <td>-0.213959</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4f43f48cb7</th>\n",
       "      <td>0.950368</td>\n",
       "      <td>2.097777</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>-1.280050</td>\n",
       "      <td>-2.898667</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>0.928971</td>\n",
       "      <td>1.795747</td>\n",
       "      <td>-0.761324</td>\n",
       "      <td>0.350584</td>\n",
       "      <td>-0.277059</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c5792264c8</th>\n",
       "      <td>-0.157904</td>\n",
       "      <td>0.055165</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.004736</td>\n",
       "      <td>0.201673</td>\n",
       "      <td>-0.570042</td>\n",
       "      <td>-0.805275</td>\n",
       "      <td>1.237357</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84880145bd</th>\n",
       "      <td>0.233598</td>\n",
       "      <td>0.990752</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>-0.169745</td>\n",
       "      <td>-0.654489</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.053363</td>\n",
       "      <td>0.588458</td>\n",
       "      <td>1.740055</td>\n",
       "      <td>0.692624</td>\n",
       "      <td>-0.718764</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>2.226620</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49eb365a88</th>\n",
       "      <td>-0.179916</td>\n",
       "      <td>-0.009647</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>-0.479753</td>\n",
       "      <td>-0.708473</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.210638</td>\n",
       "      <td>-0.028665</td>\n",
       "      <td>-1.065413</td>\n",
       "      <td>-0.734508</td>\n",
       "      <td>-1.665274</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>2.226620</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1b55a9f080</th>\n",
       "      <td>0.346449</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>-4.612494</td>\n",
       "      <td>-4.710975</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>1.005128</td>\n",
       "      <td>0.508723</td>\n",
       "      <td>-0.800561</td>\n",
       "      <td>0.794843</td>\n",
       "      <td>0.038444</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9961481e46</th>\n",
       "      <td>-0.638796</td>\n",
       "      <td>-0.592951</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.598505</td>\n",
       "      <td>-0.541346</td>\n",
       "      <td>0.121515</td>\n",
       "      <td>-0.243072</td>\n",
       "      <td>1.426659</td>\n",
       "      <td>1.309908</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112021 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            regular_points_received_mean  regular_points_received_sum  \\\n",
       "client_id                                                               \n",
       "fd1ab717e8                     -0.344139                     0.318593   \n",
       "5be3f83065                      1.015586                     0.640561   \n",
       "1c48fc99b2                     -0.516362                     0.411629   \n",
       "fcce9d3197                     -0.494128                     0.195242   \n",
       "4f43f48cb7                      0.950368                     2.097777   \n",
       "...                                  ...                          ...   \n",
       "c5792264c8                     -0.157904                     0.055165   \n",
       "84880145bd                      0.233598                     0.990752   \n",
       "49eb365a88                     -0.179916                    -0.009647   \n",
       "1b55a9f080                      0.346449                     0.209877   \n",
       "9961481e46                     -0.638796                    -0.592951   \n",
       "\n",
       "            express_points_received_mean  express_points_received_sum  \\\n",
       "client_id                                                               \n",
       "fd1ab717e8                     -0.072084                    -0.102507   \n",
       "5be3f83065                     -0.072084                    -0.102507   \n",
       "1c48fc99b2                     -0.072084                    -0.102507   \n",
       "fcce9d3197                     -0.072084                    -0.102507   \n",
       "4f43f48cb7                     -0.072084                    -0.102507   \n",
       "...                                  ...                          ...   \n",
       "c5792264c8                     -0.072084                    -0.102507   \n",
       "84880145bd                     -0.072084                    -0.102507   \n",
       "49eb365a88                     -0.072084                    -0.102507   \n",
       "1b55a9f080                     -0.072084                    -0.102507   \n",
       "9961481e46                     -0.072084                    -0.102507   \n",
       "\n",
       "            regular_points_spent_mean  regular_points_spent_sum  \\\n",
       "client_id                                                         \n",
       "fd1ab717e8                   0.433102                  0.563999   \n",
       "5be3f83065                   0.433102                  0.563999   \n",
       "1c48fc99b2                   0.189674                 -0.369147   \n",
       "fcce9d3197                   0.026531                 -0.654489   \n",
       "4f43f48cb7                  -1.280050                 -2.898667   \n",
       "...                               ...                       ...   \n",
       "c5792264c8                   0.433102                  0.563999   \n",
       "84880145bd                  -0.169745                 -0.654489   \n",
       "49eb365a88                  -0.479753                 -0.708473   \n",
       "1b55a9f080                  -4.612494                 -4.710975   \n",
       "9961481e46                   0.433102                  0.563999   \n",
       "\n",
       "            express_points_spent_mean  express_points_spent_sum  \\\n",
       "client_id                                                         \n",
       "fd1ab717e8                   0.246932                  0.395964   \n",
       "5be3f83065                   0.246932                  0.395964   \n",
       "1c48fc99b2                   0.246932                  0.395964   \n",
       "fcce9d3197                   0.246932                  0.395964   \n",
       "4f43f48cb7                   0.246932                  0.395964   \n",
       "...                               ...                       ...   \n",
       "c5792264c8                   0.246932                  0.395964   \n",
       "84880145bd                   0.246932                  0.395964   \n",
       "49eb365a88                   0.246932                  0.395964   \n",
       "1b55a9f080                   0.246932                  0.395964   \n",
       "9961481e46                   0.246932                  0.395964   \n",
       "\n",
       "            purchase_mean  purchase_sum  first_issue_date  first_redeem_date  \\\n",
       "client_id                                                                      \n",
       "fd1ab717e8      -0.674769      0.016709          1.146590           0.881336   \n",
       "5be3f83065       0.588284      0.162789          1.852862           1.113294   \n",
       "1c48fc99b2      -0.434654      1.097419         -1.085032          -1.548328   \n",
       "fcce9d3197      -0.421486      0.670231         -0.834894          -1.438246   \n",
       "4f43f48cb7       0.928971      1.795747         -0.761324           0.350584   \n",
       "...                   ...           ...               ...                ...   \n",
       "c5792264c8      -0.004736      0.201673         -0.570042          -0.805275   \n",
       "84880145bd      -0.053363      0.588458          1.740055           0.692624   \n",
       "49eb365a88      -0.210638     -0.028665         -1.065413          -0.734508   \n",
       "1b55a9f080       1.005128      0.508723         -0.800561           0.794843   \n",
       "9961481e46      -0.598505     -0.541346          0.121515          -0.243072   \n",
       "\n",
       "                 age  gender_F  gender_M  no_redeem  \n",
       "client_id                                            \n",
       "fd1ab717e8  1.426659  1.309908 -0.449111  -0.311067  \n",
       "5be3f83065  1.300457  1.309908 -0.449111  -0.311067  \n",
       "1c48fc99b2  0.732551  1.309908 -0.449111  -0.311067  \n",
       "fcce9d3197 -0.213959 -0.763412 -0.449111  -0.311067  \n",
       "4f43f48cb7 -0.277059 -0.763412 -0.449111  -0.311067  \n",
       "...              ...       ...       ...        ...  \n",
       "c5792264c8  1.237357 -0.763412 -0.449111  -0.311067  \n",
       "84880145bd -0.718764 -0.763412  2.226620  -0.311067  \n",
       "49eb365a88 -1.665274 -0.763412  2.226620  -0.311067  \n",
       "1b55a9f080  0.038444 -0.763412 -0.449111  -0.311067  \n",
       "9961481e46  1.426659  1.309908 -0.449111  -0.311067  \n",
       "\n",
       "[112021 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_full.loc[indices_train, x_cols]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ebda15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client_id\n",
       "fd1ab717e8    1\n",
       "5be3f83065    1\n",
       "1c48fc99b2    0\n",
       "fcce9d3197    1\n",
       "4f43f48cb7    0\n",
       "             ..\n",
       "c5792264c8    0\n",
       "84880145bd    0\n",
       "49eb365a88    0\n",
       "1b55a9f080    1\n",
       "9961481e46    1\n",
       "Name: treatment_flg, Length: 112021, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treat_train = df_full.loc[indices_train, 'treatment_flg']\n",
    "treat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7fb237b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client_id\n",
       "fd1ab717e8    1\n",
       "5be3f83065    0\n",
       "1c48fc99b2    1\n",
       "fcce9d3197    1\n",
       "4f43f48cb7    1\n",
       "             ..\n",
       "c5792264c8    1\n",
       "84880145bd    1\n",
       "49eb365a88    0\n",
       "1b55a9f080    0\n",
       "9961481e46    1\n",
       "Name: purchased, Length: 112021, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df_full.loc[indices_train, 'purchased']\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09f2db6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regular_points_received_mean</th>\n",
       "      <th>regular_points_received_sum</th>\n",
       "      <th>express_points_received_mean</th>\n",
       "      <th>express_points_received_sum</th>\n",
       "      <th>regular_points_spent_mean</th>\n",
       "      <th>regular_points_spent_sum</th>\n",
       "      <th>express_points_spent_mean</th>\n",
       "      <th>express_points_spent_sum</th>\n",
       "      <th>purchase_mean</th>\n",
       "      <th>purchase_sum</th>\n",
       "      <th>first_issue_date</th>\n",
       "      <th>first_redeem_date</th>\n",
       "      <th>age</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>no_redeem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c0582c1d5e</th>\n",
       "      <td>-0.632076</td>\n",
       "      <td>-0.346249</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>-0.081989</td>\n",
       "      <td>-0.477114</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.650816</td>\n",
       "      <td>-0.145813</td>\n",
       "      <td>0.146039</td>\n",
       "      <td>-0.018976</td>\n",
       "      <td>0.606350</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9a96a00f1d</th>\n",
       "      <td>3.342703</td>\n",
       "      <td>4.653655</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>-1.166699</td>\n",
       "      <td>-2.112048</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>4.101678</td>\n",
       "      <td>4.545778</td>\n",
       "      <td>-0.839799</td>\n",
       "      <td>-1.064754</td>\n",
       "      <td>1.111155</td>\n",
       "      <td>1.309908</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55bca71943</th>\n",
       "      <td>1.087089</td>\n",
       "      <td>-0.490507</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>1.695660</td>\n",
       "      <td>-0.586874</td>\n",
       "      <td>0.494270</td>\n",
       "      <td>1.836689</td>\n",
       "      <td>-0.908066</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>3.214739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5bb5a27171</th>\n",
       "      <td>-0.332497</td>\n",
       "      <td>0.276779</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>-0.689661</td>\n",
       "      <td>-2.096624</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.494773</td>\n",
       "      <td>0.221219</td>\n",
       "      <td>-0.918273</td>\n",
       "      <td>-1.284918</td>\n",
       "      <td>-0.340160</td>\n",
       "      <td>1.309908</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d9c7b97fba</th>\n",
       "      <td>-0.322875</td>\n",
       "      <td>-0.031599</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>-0.203130</td>\n",
       "      <td>-0.500250</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.202260</td>\n",
       "      <td>0.168226</td>\n",
       "      <td>-1.065413</td>\n",
       "      <td>0.708350</td>\n",
       "      <td>-0.277059</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>2.226620</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f68c84f07b</th>\n",
       "      <td>-0.460273</td>\n",
       "      <td>-0.358793</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.239603</td>\n",
       "      <td>-0.144946</td>\n",
       "      <td>1.504631</td>\n",
       "      <td>1.836689</td>\n",
       "      <td>-1.728375</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>2.226620</td>\n",
       "      <td>3.214739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704cff2628</th>\n",
       "      <td>-0.720892</td>\n",
       "      <td>-0.711076</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.383924</td>\n",
       "      <td>0.533151</td>\n",
       "      <td>-1.054759</td>\n",
       "      <td>-1.443925</td>\n",
       "      <td>-0.743242</td>\n",
       "      <td>-0.749825</td>\n",
       "      <td>-0.055052</td>\n",
       "      <td>-0.431783</td>\n",
       "      <td>-0.277059</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feff930002</th>\n",
       "      <td>-0.559068</td>\n",
       "      <td>-0.213490</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>-0.145962</td>\n",
       "      <td>-0.646777</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.497624</td>\n",
       "      <td>0.077391</td>\n",
       "      <td>-0.829989</td>\n",
       "      <td>-0.667673</td>\n",
       "      <td>-1.097368</td>\n",
       "      <td>1.309908</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa31a8a3bb</th>\n",
       "      <td>-0.816853</td>\n",
       "      <td>-0.807248</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>-0.993715</td>\n",
       "      <td>-0.956608</td>\n",
       "      <td>2.083381</td>\n",
       "      <td>1.836689</td>\n",
       "      <td>0.164645</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>3.214739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cf760d447c</th>\n",
       "      <td>-0.588108</td>\n",
       "      <td>0.146110</td>\n",
       "      <td>-0.072084</td>\n",
       "      <td>-0.102507</td>\n",
       "      <td>0.377777</td>\n",
       "      <td>0.363488</td>\n",
       "      <td>0.066698</td>\n",
       "      <td>-1.075947</td>\n",
       "      <td>-0.715543</td>\n",
       "      <td>0.365621</td>\n",
       "      <td>-0.010910</td>\n",
       "      <td>-0.561523</td>\n",
       "      <td>-0.971167</td>\n",
       "      <td>-0.763412</td>\n",
       "      <td>-0.449111</td>\n",
       "      <td>-0.311067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28006 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            regular_points_received_mean  regular_points_received_sum  \\\n",
       "client_id                                                               \n",
       "c0582c1d5e                     -0.632076                    -0.346249   \n",
       "9a96a00f1d                      3.342703                     4.653655   \n",
       "55bca71943                      1.087089                    -0.490507   \n",
       "5bb5a27171                     -0.332497                     0.276779   \n",
       "d9c7b97fba                     -0.322875                    -0.031599   \n",
       "...                                  ...                          ...   \n",
       "f68c84f07b                     -0.460273                    -0.358793   \n",
       "704cff2628                     -0.720892                    -0.711076   \n",
       "feff930002                     -0.559068                    -0.213490   \n",
       "fa31a8a3bb                     -0.816853                    -0.807248   \n",
       "cf760d447c                     -0.588108                     0.146110   \n",
       "\n",
       "            express_points_received_mean  express_points_received_sum  \\\n",
       "client_id                                                               \n",
       "c0582c1d5e                     -0.072084                    -0.102507   \n",
       "9a96a00f1d                     -0.072084                    -0.102507   \n",
       "55bca71943                     -0.072084                    -0.102507   \n",
       "5bb5a27171                     -0.072084                    -0.102507   \n",
       "d9c7b97fba                     -0.072084                    -0.102507   \n",
       "...                                  ...                          ...   \n",
       "f68c84f07b                     -0.072084                    -0.102507   \n",
       "704cff2628                     -0.072084                    -0.102507   \n",
       "feff930002                     -0.072084                    -0.102507   \n",
       "fa31a8a3bb                     -0.072084                    -0.102507   \n",
       "cf760d447c                     -0.072084                    -0.102507   \n",
       "\n",
       "            regular_points_spent_mean  regular_points_spent_sum  \\\n",
       "client_id                                                         \n",
       "c0582c1d5e                  -0.081989                 -0.477114   \n",
       "9a96a00f1d                  -1.166699                 -2.112048   \n",
       "55bca71943                   0.433102                  0.563999   \n",
       "5bb5a27171                  -0.689661                 -2.096624   \n",
       "d9c7b97fba                  -0.203130                 -0.500250   \n",
       "...                               ...                       ...   \n",
       "f68c84f07b                   0.433102                  0.563999   \n",
       "704cff2628                   0.383924                  0.533151   \n",
       "feff930002                  -0.145962                 -0.646777   \n",
       "fa31a8a3bb                   0.433102                  0.563999   \n",
       "cf760d447c                   0.377777                  0.363488   \n",
       "\n",
       "            express_points_spent_mean  express_points_spent_sum  \\\n",
       "client_id                                                         \n",
       "c0582c1d5e                   0.246932                  0.395964   \n",
       "9a96a00f1d                   0.246932                  0.395964   \n",
       "55bca71943                   0.246932                  0.395964   \n",
       "5bb5a27171                   0.246932                  0.395964   \n",
       "d9c7b97fba                   0.246932                  0.395964   \n",
       "...                               ...                       ...   \n",
       "f68c84f07b                   0.246932                  0.395964   \n",
       "704cff2628                  -1.054759                 -1.443925   \n",
       "feff930002                   0.246932                  0.395964   \n",
       "fa31a8a3bb                   0.246932                  0.395964   \n",
       "cf760d447c                   0.066698                 -1.075947   \n",
       "\n",
       "            purchase_mean  purchase_sum  first_issue_date  first_redeem_date  \\\n",
       "client_id                                                                      \n",
       "c0582c1d5e      -0.650816     -0.145813          0.146039          -0.018976   \n",
       "9a96a00f1d       4.101678      4.545778         -0.839799          -1.064754   \n",
       "55bca71943       1.695660     -0.586874          0.494270           1.836689   \n",
       "5bb5a27171      -0.494773      0.221219         -0.918273          -1.284918   \n",
       "d9c7b97fba      -0.202260      0.168226         -1.065413           0.708350   \n",
       "...                   ...           ...               ...                ...   \n",
       "f68c84f07b      -0.239603     -0.144946          1.504631           1.836689   \n",
       "704cff2628      -0.743242     -0.749825         -0.055052          -0.431783   \n",
       "feff930002      -0.497624      0.077391         -0.829989          -0.667673   \n",
       "fa31a8a3bb      -0.993715     -0.956608          2.083381           1.836689   \n",
       "cf760d447c      -0.715543      0.365621         -0.010910          -0.561523   \n",
       "\n",
       "                 age  gender_F  gender_M  no_redeem  \n",
       "client_id                                            \n",
       "c0582c1d5e  0.606350 -0.763412 -0.449111  -0.311067  \n",
       "9a96a00f1d  1.111155  1.309908 -0.449111  -0.311067  \n",
       "55bca71943 -0.908066 -0.763412 -0.449111   3.214739  \n",
       "5bb5a27171 -0.340160  1.309908 -0.449111  -0.311067  \n",
       "d9c7b97fba -0.277059 -0.763412  2.226620  -0.311067  \n",
       "...              ...       ...       ...        ...  \n",
       "f68c84f07b -1.728375 -0.763412  2.226620   3.214739  \n",
       "704cff2628 -0.277059 -0.763412 -0.449111  -0.311067  \n",
       "feff930002 -1.097368  1.309908 -0.449111  -0.311067  \n",
       "fa31a8a3bb  0.164645 -0.763412 -0.449111   3.214739  \n",
       "cf760d447c -0.971167 -0.763412 -0.449111  -0.311067  \n",
       "\n",
       "[28006 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = df_full.loc[indices_val, x_cols]\n",
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "994bca45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client_id\n",
       "c0582c1d5e    1\n",
       "9a96a00f1d    0\n",
       "55bca71943    0\n",
       "5bb5a27171    0\n",
       "d9c7b97fba    0\n",
       "             ..\n",
       "f68c84f07b    0\n",
       "704cff2628    1\n",
       "feff930002    1\n",
       "fa31a8a3bb    0\n",
       "cf760d447c    1\n",
       "Name: treatment_flg, Length: 28006, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treat_val = df_full.loc[indices_val, 'treatment_flg']\n",
    "treat_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9762aaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client_id\n",
       "c0582c1d5e    1\n",
       "9a96a00f1d    1\n",
       "55bca71943    0\n",
       "5bb5a27171    1\n",
       "d9c7b97fba    0\n",
       "             ..\n",
       "f68c84f07b    1\n",
       "704cff2628    1\n",
       "feff930002    1\n",
       "fa31a8a3bb    0\n",
       "cf760d447c    1\n",
       "Name: purchased, Length: 28006, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = df_full.loc[indices_val, 'purchased']\n",
    "y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04823fba",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbbbaef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = XGBClassifier(random_state=8, \n",
    "                     use_label_encoder=False,\n",
    "                     learning_rate=0.1,\n",
    "                     max_depth=2,\n",
    "                     n_estimators=50,\n",
    "                     reg_alpha=0,\n",
    "                     reg_lambda=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2160caec",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = AdaBoostClassifier(random_state=8,\n",
    "                              base_estimator=DecisionTreeClassifier(random_state=8, \n",
    "                                                                    max_depth=2),\n",
    "                               learning_rate=0.5,\n",
    "                               n_estimators=15\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81af2984",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[('xgboost', clf1), ('ada', clf2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e789aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = StackingClassifier(estimators=estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08c1a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassTransformation(estimator = estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6cf40d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "uplift_scorer = metrics.make_uplift_scorer(\"qini_auc_score\", treat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc192aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'estimator__final_estimator': [\n",
    "        LogisticRegression(random_state=8,\n",
    "                           penalty='l2',\n",
    "                           solver='saga',\n",
    "                           max_iter=50\n",
    "                          ),\n",
    "        LogisticRegression(random_state=8,\n",
    "                           penalty='l2',\n",
    "                           solver='saga',\n",
    "                           max_iter=100\n",
    "                          ),\n",
    "        LogisticRegression(random_state=8,\n",
    "                           penalty='l2',\n",
    "                           solver='saga',\n",
    "                           max_iter=200\n",
    "                          )\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c848c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(model,\n",
    "                           param_grid=params,\n",
    "                           scoring=uplift_scorer,\n",
    "                           cv=5,\n",
    "                           verbose=4\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f559a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[17:23:24] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:23:26] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:23:27] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:23:28] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:23:28] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:23:29] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5] END estimator__final_estimator=LogisticRegression(max_iter=50, random_state=8, solver='saga');, score=0.026 total time=  14.9s\n",
      "[17:23:39] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:23:41] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:23:42] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:23:43] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:23:43] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:23:44] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END estimator__final_estimator=LogisticRegression(max_iter=50, random_state=8, solver='saga');, score=0.027 total time=  14.8s\n",
      "[17:23:53] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:23:56] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:23:57] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:23:58] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:23:58] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:23:59] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5] END estimator__final_estimator=LogisticRegression(max_iter=50, random_state=8, solver='saga');, score=0.022 total time=  14.9s\n",
      "[17:24:08] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:24:11] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:12] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:12] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:13] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:13] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END estimator__final_estimator=LogisticRegression(max_iter=50, random_state=8, solver='saga');, score=0.026 total time=  14.5s\n",
      "[17:24:23] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:24:26] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:26] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:27] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:27] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:28] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5] END estimator__final_estimator=LogisticRegression(max_iter=50, random_state=8, solver='saga');, score=0.026 total time=  14.6s\n",
      "[17:24:37] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:24:40] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:41] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:42] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:42] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:43] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5] END estimator__final_estimator=LogisticRegression(random_state=8, solver='saga');, score=0.026 total time=  14.7s\n",
      "[17:24:52] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:24:55] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:56] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:56] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:57] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:57] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END estimator__final_estimator=LogisticRegression(random_state=8, solver='saga');, score=0.027 total time=  14.7s\n",
      "[17:25:07] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:25:10] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:10] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:11] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:12] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:12] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5] END estimator__final_estimator=LogisticRegression(random_state=8, solver='saga');, score=0.022 total time=  14.7s\n",
      "[17:25:21] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:25:24] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:25] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:26] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:26] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:27] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END estimator__final_estimator=LogisticRegression(random_state=8, solver='saga');, score=0.026 total time=  14.6s\n",
      "[17:25:36] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:25:39] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:40] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:40] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:41] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:42] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5] END estimator__final_estimator=LogisticRegression(random_state=8, solver='saga');, score=0.026 total time=  14.8s\n",
      "[17:25:51] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:25:54] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:54] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:55] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:56] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:56] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5] END estimator__final_estimator=LogisticRegression(max_iter=200, random_state=8, solver='saga');, score=0.026 total time=  14.7s\n",
      "[17:26:05] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:26:08] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:09] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:10] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:10] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:11] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5] END estimator__final_estimator=LogisticRegression(max_iter=200, random_state=8, solver='saga');, score=0.027 total time=  14.7s\n",
      "[17:26:20] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:26:23] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:24] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:24] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:25] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:26] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5] END estimator__final_estimator=LogisticRegression(max_iter=200, random_state=8, solver='saga');, score=0.022 total time=  14.6s\n",
      "[17:26:35] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:26:38] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:38] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:39] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:40] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:40] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5] END estimator__final_estimator=LogisticRegression(max_iter=200, random_state=8, solver='saga');, score=0.026 total time=  14.7s\n",
      "[17:26:49] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:26:52] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:53] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:54] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:54] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:26:55] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5] END estimator__final_estimator=LogisticRegression(max_iter=200, random_state=8, solver='saga');, score=0.026 total time=  14.7s\n",
      "[17:27:04] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:27:08] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:27:09] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:27:09] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:27:10] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:27:11] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 7min 24s, sys: 4.22 s, total: 7min 28s\n",
      "Wall time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%chime\n",
    "grid_search = grid_search.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    treatment=treat_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cae536d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025392529578773824"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc38faa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__final_estimator': LogisticRegression(max_iter=50, random_state=8, solver='saga')}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ee209",
   "metadata": {},
   "source": [
    "### Validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa012c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:27:40] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/MyCode/Git/Kaggle_CFT/env/lib/python3.10/site-packages/xgboost/data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:27:43] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:27:44] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:27:45] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:27:46] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:27:46] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ClassTransformation(estimator=StackingClassifier(estimators=[(&#x27;xgboost&#x27;,\n",
       "                                                              XGBClassifier(base_score=None,\n",
       "                                                                            booster=None,\n",
       "                                                                            colsample_bylevel=None,\n",
       "                                                                            colsample_bynode=None,\n",
       "                                                                            colsample_bytree=None,\n",
       "                                                                            enable_categorical=False,\n",
       "                                                                            gamma=None,\n",
       "                                                                            gpu_id=None,\n",
       "                                                                            importance_type=None,\n",
       "                                                                            interaction_constraints=None,\n",
       "                                                                            learning_rate=0.1,\n",
       "                                                                            max_delta_step=None,\n",
       "                                                                            max_depth=2,\n",
       "                                                                            min_child_weight=Non...\n",
       "                                                                            reg_lambda=0.05,\n",
       "                                                                            scale_pos_weight=None,\n",
       "                                                                            subsample=None,\n",
       "                                                                            tree_method=None,\n",
       "                                                                            use_label_encoder=False,\n",
       "                                                                            validate_parameters=None,\n",
       "                                                                            verbosity=None)),\n",
       "                                                             (&#x27;ada&#x27;,\n",
       "                                                              AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2,\n",
       "                                                                                                                       random_state=8),\n",
       "                                                                                 learning_rate=0.5,\n",
       "                                                                                 n_estimators=15,\n",
       "                                                                                 random_state=8))],\n",
       "                                                 final_estimator=LogisticRegression(max_iter=50,\n",
       "                                                                                    random_state=8,\n",
       "                                                                                    solver=&#x27;saga&#x27;)))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ClassTransformation</label><div class=\"sk-toggleable__content\"><pre>ClassTransformation(estimator=StackingClassifier(estimators=[(&#x27;xgboost&#x27;,\n",
       "                                                              XGBClassifier(base_score=None,\n",
       "                                                                            booster=None,\n",
       "                                                                            colsample_bylevel=None,\n",
       "                                                                            colsample_bynode=None,\n",
       "                                                                            colsample_bytree=None,\n",
       "                                                                            enable_categorical=False,\n",
       "                                                                            gamma=None,\n",
       "                                                                            gpu_id=None,\n",
       "                                                                            importance_type=None,\n",
       "                                                                            interaction_constraints=None,\n",
       "                                                                            learning_rate=0.1,\n",
       "                                                                            max_delta_step=None,\n",
       "                                                                            max_depth=2,\n",
       "                                                                            min_child_weight=Non...\n",
       "                                                                            reg_lambda=0.05,\n",
       "                                                                            scale_pos_weight=None,\n",
       "                                                                            subsample=None,\n",
       "                                                                            tree_method=None,\n",
       "                                                                            use_label_encoder=False,\n",
       "                                                                            validate_parameters=None,\n",
       "                                                                            verbosity=None)),\n",
       "                                                             (&#x27;ada&#x27;,\n",
       "                                                              AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2,\n",
       "                                                                                                                       random_state=8),\n",
       "                                                                                 learning_rate=0.5,\n",
       "                                                                                 n_estimators=15,\n",
       "                                                                                 random_state=8))],\n",
       "                                                 final_estimator=LogisticRegression(max_iter=50,\n",
       "                                                                                    random_state=8,\n",
       "                                                                                    solver=&#x27;saga&#x27;)))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;xgboost&#x27;,\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              gamma=None, gpu_id=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=0.1,\n",
       "                                              max_delta_step=None, max_depth=2,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constra...\n",
       "                                              reg_alpha=0, reg_lambda=0.05,\n",
       "                                              scale_pos_weight=None,\n",
       "                                              subsample=None, tree_method=None,\n",
       "                                              use_label_encoder=False,\n",
       "                                              validate_parameters=None,\n",
       "                                              verbosity=None)),\n",
       "                               (&#x27;ada&#x27;,\n",
       "                                AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2,\n",
       "                                                                                         random_state=8),\n",
       "                                                   learning_rate=0.5,\n",
       "                                                   n_estimators=15,\n",
       "                                                   random_state=8))],\n",
       "                   final_estimator=LogisticRegression(max_iter=50,\n",
       "                                                      random_state=8,\n",
       "                                                      solver=&#x27;saga&#x27;))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None,\n",
       "              enable_categorical=False, gamma=None, gpu_id=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=None, max_depth=2,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=50, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=8, reg_alpha=0, reg_lambda=0.05,\n",
       "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "              use_label_encoder=False, validate_parameters=None,\n",
       "              verbosity=None)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>ada</label></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=2, random_state=8)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=2, random_state=8)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=50, random_state=8, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ClassTransformation(estimator=StackingClassifier(estimators=[('xgboost',\n",
       "                                                              XGBClassifier(base_score=None,\n",
       "                                                                            booster=None,\n",
       "                                                                            colsample_bylevel=None,\n",
       "                                                                            colsample_bynode=None,\n",
       "                                                                            colsample_bytree=None,\n",
       "                                                                            enable_categorical=False,\n",
       "                                                                            gamma=None,\n",
       "                                                                            gpu_id=None,\n",
       "                                                                            importance_type=None,\n",
       "                                                                            interaction_constraints=None,\n",
       "                                                                            learning_rate=0.1,\n",
       "                                                                            max_delta_step=None,\n",
       "                                                                            max_depth=2,\n",
       "                                                                            min_child_weight=Non...\n",
       "                                                                            reg_lambda=0.05,\n",
       "                                                                            scale_pos_weight=None,\n",
       "                                                                            subsample=None,\n",
       "                                                                            tree_method=None,\n",
       "                                                                            use_label_encoder=False,\n",
       "                                                                            validate_parameters=None,\n",
       "                                                                            verbosity=None)),\n",
       "                                                             ('ada',\n",
       "                                                              AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2,\n",
       "                                                                                                                       random_state=8),\n",
       "                                                                                 learning_rate=0.5,\n",
       "                                                                                 n_estimators=15,\n",
       "                                                                                 random_state=8))],\n",
       "                                                 final_estimator=LogisticRegression(max_iter=50,\n",
       "                                                                                    random_state=8,\n",
       "                                                                                    solver='saga')))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_params(**grid_search.best_params_)\n",
    "\n",
    "model.fit(\n",
    "    X=X_train, \n",
    "    y=y_train, \n",
    "    treatment=treat_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f78e3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04703109,  0.04307288, -0.02018485, ..., -0.01151295,\n",
       "        0.05679277,  0.00650434])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = model.predict(X_val)\n",
    "y_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c42dc6de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_qini_curve(y_val, y_pred_val, treat_val);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44b8d9a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022827613515471003"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.qini_auc_score(y_val, y_pred_val, treat_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
